{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+jvPAX4k9zHlhPGlu9MJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nidhi89717/ML/blob/main/10-Naive-Bayes-and-NLP/01_Feature_Extraction_From_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction from Text"
      ],
      "metadata": {
        "id": "K1_dwnMTdo-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part One: Core Concepts on Feature Extraction\n",
        "\n",
        "\n",
        "In this section we'll use basic Python to build a rudimentary NLP system. We'll build a *corpus of documents* (two small text files), create a *vocabulary* from all the words in both documents, and then demonstrate a *Bag of Words* technique to extract features from each document.<br>\n",
        "<div class=\"alert alert-info\" style=\"margin: 20px\">This first section is for illustration only!\n"
      ],
      "metadata": {
        "id": "bdBTzkQKdy2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PA-7pSF5jF1",
        "outputId": "bd2f4f28-ee9e-46cc-be6a-d397c724ee6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/My Drive/csv_files/One.txt') as mytext:\n",
        "  a = mytext.read()"
      ],
      "metadata": {
        "id": "PrgHgNqn7NZn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zkwx7EC_7mYG",
        "outputId": "84983f52-f884-4bf2-9e11-eccf956eea3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a story about dogs\\nour canine pets\\nDogs are furry animals\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEISH9pa7m_G",
        "outputId": "64c96a14-aca1-4951-99a7-bf3472de27ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a story about dogs\n",
            "our canine pets\n",
            "Dogs are furry animals\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/My Drive/csv_files/One.txt') as mytext:\n",
        "  word_one = mytext.read().lower().split()\n",
        "  unique_word_one = set(word_one)"
      ],
      "metadata": {
        "id": "5UKdEg0q7o-_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_word_one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97PfYq0-89Yn",
        "outputId": "087b1110-dd59-47a1-c822-b8d067f46ced"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'animals',\n",
              " 'are',\n",
              " 'canine',\n",
              " 'dogs',\n",
              " 'furry',\n",
              " 'is',\n",
              " 'our',\n",
              " 'pets',\n",
              " 'story',\n",
              " 'this'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/My Drive/csv_files/Two.txt') as mytext:\n",
        "  word_two = mytext.read().lower().split()\n",
        "  unique_word_two = set(word_two)"
      ],
      "metadata": {
        "id": "afWP19Da9d9a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_word_two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28n_uNAO9kg8",
        "outputId": "02889acf-e333-448d-9ba4-40e8f737961c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'catching',\n",
              " 'fun',\n",
              " 'is',\n",
              " 'popular',\n",
              " 'sport',\n",
              " 'story',\n",
              " 'surfing',\n",
              " 'this',\n",
              " 'water',\n",
              " 'waves'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get all unique words across all documents**"
      ],
      "metadata": {
        "id": "4OcQ6krFeOVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uni_words = set()\n",
        "uni_words.update(unique_word_one)"
      ],
      "metadata": {
        "id": "M9PCzb-7-Jhi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni_words.update(unique_word_two)"
      ],
      "metadata": {
        "id": "EG0GUSD2-R9t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L9NyASH-Yx4",
        "outputId": "dfde5b8e-89e8-4226-d06b-2867164d956c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'animals',\n",
              " 'are',\n",
              " 'canine',\n",
              " 'catching',\n",
              " 'dogs',\n",
              " 'fun',\n",
              " 'furry',\n",
              " 'is',\n",
              " 'our',\n",
              " 'pets',\n",
              " 'popular',\n",
              " 'sport',\n",
              " 'story',\n",
              " 'surfing',\n",
              " 'this',\n",
              " 'water',\n",
              " 'waves'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_vocab = dict()\n",
        "i = 0\n",
        "\n",
        "for word in uni_words:\n",
        "  full_vocab[word] = i\n",
        "  i = i+1"
      ],
      "metadata": {
        "id": "2xiOuS7i-0wl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECkhdeLB_DKZ",
        "outputId": "ccfb9b07-ea31-45f1-ed94-6e4f5c9e1892"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'animals': 0,\n",
              " 'story': 1,\n",
              " 'canine': 2,\n",
              " 'pets': 3,\n",
              " 'a': 4,\n",
              " 'about': 5,\n",
              " 'popular': 6,\n",
              " 'fun': 7,\n",
              " 'surfing': 8,\n",
              " 'sport': 9,\n",
              " 'waves': 10,\n",
              " 'is': 11,\n",
              " 'this': 12,\n",
              " 'dogs': 13,\n",
              " 'are': 14,\n",
              " 'furry': 15,\n",
              " 'catching': 16,\n",
              " 'water': 17,\n",
              " 'our': 18}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words to Frequency Counts\n",
        "\n",
        "Now that we've encapsulated our \"entire language\" in a dictionary, let's perform *feature extraction* on each of our original documents:"
      ],
      "metadata": {
        "id": "Qg1vNBP0eWEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Empty counts per doc**"
      ],
      "metadata": {
        "id": "Z4L5fJgreW-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_freq = [0]*len(full_vocab)\n",
        "two_freq = [0]*len(full_vocab)\n",
        "all_words = ['']*len(full_vocab)"
      ],
      "metadata": {
        "id": "6Wc8J8HO_4SL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/My Drive/csv_files/One.txt') as mytext:\n",
        "  one_text = mytext.read().lower().split()"
      ],
      "metadata": {
        "id": "d2siELpOAGhQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add in counts per word per doc:**"
      ],
      "metadata": {
        "id": "jVuKmRTzegpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in one_text:\n",
        "  word_ind = full_vocab[word]\n",
        "  one_freq[word_ind] +=1"
      ],
      "metadata": {
        "id": "Sw0b5_gcAdKR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KdPhgBQBF6O",
        "outputId": "32cd80a3-b4e5-4a61-e7cd-504caaf38731"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/My Drive/csv_files/Two.txt') as mytext:\n",
        "  two_text = mytext.read().lower().split()"
      ],
      "metadata": {
        "id": "WRXQNitIBNsr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in two_text:\n",
        "  word_ind = full_vocab[word]\n",
        "  two_freq[word_ind] +=1"
      ],
      "metadata": {
        "id": "v3eH7DddBW7P"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "two_freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qXP6hJVBf3v",
        "outputId": "41fcb36f-9959-4ee3-cee0-a478a74b502f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 3, 1, 0, 0, 0, 1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in full_vocab:\n",
        "  word_ind = full_vocab[words]\n",
        "  all_words[word_ind] = words"
      ],
      "metadata": {
        "id": "SU04WDutB-sk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4KLDQBYCeKo",
        "outputId": "877869a5-67d2-402c-9a34-a0488709d23c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['animals',\n",
              " 'story',\n",
              " 'canine',\n",
              " 'pets',\n",
              " 'a',\n",
              " 'about',\n",
              " 'popular',\n",
              " 'fun',\n",
              " 'surfing',\n",
              " 'sport',\n",
              " 'waves',\n",
              " 'is',\n",
              " 'this',\n",
              " 'dogs',\n",
              " 'are',\n",
              " 'furry',\n",
              " 'catching',\n",
              " 'water',\n",
              " 'our']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "bow = pd.DataFrame(data=[one_freq,two_freq],columns=all_words)"
      ],
      "metadata": {
        "id": "MNHOr1CCEwfq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "9lEi2iC7E-eF",
        "outputId": "5234abb8-1acf-4fba-af23-cd5cd5619879"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   animals  story  canine  pets  a  about  popular  fun  surfing  sport  \\\n",
              "0        1      1       1     1  1      1        0    0        0      0   \n",
              "1        0      1       0     0  1      1        1    1        2      1   \n",
              "\n",
              "   waves  is  this  dogs  are  furry  catching  water  our  \n",
              "0      0   1     1     2    1      1         0      0    1  \n",
              "1      1   3     1     0    0      0         1      1    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41181bcf-136e-4323-98e6-91e0a851518b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>animals</th>\n",
              "      <th>story</th>\n",
              "      <th>canine</th>\n",
              "      <th>pets</th>\n",
              "      <th>a</th>\n",
              "      <th>about</th>\n",
              "      <th>popular</th>\n",
              "      <th>fun</th>\n",
              "      <th>surfing</th>\n",
              "      <th>sport</th>\n",
              "      <th>waves</th>\n",
              "      <th>is</th>\n",
              "      <th>this</th>\n",
              "      <th>dogs</th>\n",
              "      <th>are</th>\n",
              "      <th>furry</th>\n",
              "      <th>catching</th>\n",
              "      <th>water</th>\n",
              "      <th>our</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41181bcf-136e-4323-98e6-91e0a851518b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41181bcf-136e-4323-98e6-91e0a851518b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41181bcf-136e-4323-98e6-91e0a851518b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By comparing the vectors we see that some words are common to both, some appear only in `One.txt`, others only in `Two.txt`. Extending this logic to tens of thousands of documents, we would see the vocabulary dictionary grow to hundreds of thousands of words. Vectors would contain mostly zero values, making them **sparse matrices**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mfaQVyFDe0wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words and Tf-idf\n",
        "In the above examples, each vector can be considered a *bag of words*. By itself these may not be helpful until we consider *term frequencies*, or how often individual words appear in documents. A simple way to calculate term frequencies is to divide the number of occurrences of a word by the total number of words in the document. In this way, the number of times a word appears in large documents can be compared to that of smaller documents.\n",
        "\n",
        "However, it may be hard to differentiate documents based on term frequency if a word shows up in a majority of documents. To handle this we also consider *inverse document frequency*, which is the total number of documents divided by the number of documents that contain the word. In practice we convert this value to a logarithmic scale, as described [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Inverse_document_frequency).\n",
        "\n",
        "Together these terms become [**tf-idf**](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)."
      ],
      "metadata": {
        "id": "gHMcso7Ye_x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words and Word Stems\n",
        "Some words like \"the\" and \"and\" appear so frequently, and in so many documents, that we needn't bother counting them. Also, it may make sense to only record the root of a word, say `cat` in place of both `cat` and `cats`. This will shrink our vocab array and improve performance."
      ],
      "metadata": {
        "id": "TYoKV_4ZfF3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and Tagging\n",
        "When we created our vectors the first thing we did was split the incoming text on whitespace with `.split()`. This was a crude form of *tokenization* - that is, dividing a document into individual words. In this simple example we didn't worry about punctuation or different parts of speech. \n",
        "\n",
        "Once the text is divided, we can go back and *tag* our tokens with information about parts of speech, grammatical dependencies, etc. This adds more dimensions to our data and enables a deeper understanding of the context of specific documents. For this reason, vectors become ***high dimensional sparse matrices***."
      ],
      "metadata": {
        "id": "wukSeJJgfVwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part Two:  Feature Extraction with Scikit-Learn\n",
        "\n"
      ],
      "metadata": {
        "id": "Kg3ERsQ8ff2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scikit-Learn's Text Feature Extraction Options"
      ],
      "metadata": {
        "id": "vbGAQtLxfmJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['This is a line',\n",
        "        'This is another line',\n",
        "        'Completely different line']"
      ],
      "metadata": {
        "id": "mnvVD9RQI-6b"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer"
      ],
      "metadata": {
        "id": "as06v67gfrY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer"
      ],
      "metadata": {
        "id": "maAcvaROJOIF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(CountVectorizer)"
      ],
      "metadata": {
        "id": "mIYU81cOJXwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()"
      ],
      "metadata": {
        "id": "LVRqPd_dJdO4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix = cv.fit_transform(text)"
      ],
      "metadata": {
        "id": "NVcs-MtpKC-C"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L2YPXrwK0K4",
        "outputId": "82ec3f3f-8a2a-4270-8ac7-f19af9dac88c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, 1, 1, 1],\n",
              "        [1, 0, 0, 1, 1, 1],\n",
              "        [0, 1, 1, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHrbTN2iLD4f",
        "outputId": "bdc65e6c-e6d5-4947-c582-920b7a181077"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 5, 'is': 3, 'line': 4, 'another': 0, 'completely': 1, 'different': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2 = CountVectorizer(stop_words='english')\n",
        "sparse_matrix2 = cv2.fit_transform(text)"
      ],
      "metadata": {
        "id": "Az4Xid1rM8Qv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix2.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N-5M2pSNDwo",
        "outputId": "3f1dae3b-de02-432a-df31-43a1338b64e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 1],\n",
              "        [0, 0, 1],\n",
              "        [1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zmBlhEqNKS5",
        "outputId": "93012252-1561-4452-eeee-f58a0703b876"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'line': 2, 'completely': 0, 'different': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TfidfTransformer\n",
        "\n",
        "TfidfVectorizer is used on sentences, while TfidfTransformer is used on an existing count matrix, such as one returned by CountVectorizer"
      ],
      "metadata": {
        "id": "RENJNUnPgEOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = TfidfTransformer()"
      ],
      "metadata": {
        "id": "bbWQu-6LNz-H"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = tf.fit_transform(sparse_matrix)"
      ],
      "metadata": {
        "id": "7k9mnQV1NL6g"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0eWkg13N9uh",
        "outputId": "b49592c4-ffeb-4167-eae5-057db546e78f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.        , 0.        , 0.        , 0.61980538, 0.48133417,\n",
              "         0.61980538],\n",
              "        [0.63174505, 0.        , 0.        , 0.4804584 , 0.37311881,\n",
              "         0.4804584 ],\n",
              "        [0.        , 0.65249088, 0.65249088, 0.        , 0.38537163,\n",
              "         0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "nhl3Y4Q6OJmG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TfIdfVectorizer\n",
        "\n",
        "Does both above in a single step!"
      ],
      "metadata": {
        "id": "kyIFaqMIgTLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tv = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "IerF6FTgOQi8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_results = tv.fit_transform(text)"
      ],
      "metadata": {
        "id": "vtXK3Bk4OS7A"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_results.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16GIlB-BOY6V",
        "outputId": "a82a7fb6-ccc0-47c7-e895-8fc9c6500017"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.        , 0.        , 0.        , 0.61980538, 0.48133417,\n",
              "         0.61980538],\n",
              "        [0.63174505, 0.        , 0.        , 0.4804584 , 0.37311881,\n",
              "         0.4804584 ],\n",
              "        [0.        , 0.65249088, 0.65249088, 0.        , 0.38537163,\n",
              "         0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}